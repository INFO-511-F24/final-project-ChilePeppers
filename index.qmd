---
title: "EV Charging Trends and Predictions"
subtitle: "INFO 511 - Fall 2024 - Final Project"
author: 
  - name: "ChilePeppers"
    affiliations:
      - name: "School of Information, University of Arizona"
description: |
  This project explores trends in electric vehicle (EV) charging efficiency 
  and builds predictive models to understand charging behaviors.
format:
  html:
    code-tools: true
    code-overflow: wrap
    embed-resources: true
    fig-width: 6
    fig-height: 4  
editor: visual
execute:
  warning: False
  echo: False
jupyter: python3
---

```{python}
#| label: load-pkgs
#| message: false
import warnings
import pandas as pd
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import scipy.stats as stats 
import statsmodels.api as sm

warnings.filterwarnings("ignore")

```

# Team ChilePeppers INFO511 Term Project

## Electric Vehicle (EV) Charging Dataset Assessment

## Introduction and Data

The ChilePeppers team completed an assessment of the electric vehicle (EV) charging dataset for the INFO511 term project. The dataset was selected out of an interest to explore the evolving EV technical space and build a predictive model for charging efficiency improvements. The dataset consisted of 1320 rows and 20 columns, see Tables 1 and 2. The dataset provided charging history and profile for five electric vehicles; BMW i3, Hyundai Kona, Chevy Bolt, Nissan Leaf, and the Tesla Model 3, see Table 1. Each row in the dataset is a vehicle type with a record of a charge including location, energy consumed, charge duration, charging cost, temperature, vehicle age, charger type, and user type, see Table 2.

### Table 1 - Electric Vehicle (EV) Charging Dataset: Column Headings

```{python}

url = "https://raw.githubusercontent.com/INFO-511-F24/final-project-ChilePeppers/main/data/ev_charging_patterns.csv"
ev_charging  = pd.read_csv(url)

ev_charging.head()
```

### Table 2 - EV Charging Dataset: Column Data Types

```{python}
ev_charging.info()
```

```{python}
pd.set_option('display.max_columns', None) 
pd.set_option('display.width', 1000)    
pd.set_option('display.float_format', '{:.2f}'.format) 
summary_stats = ev_charging.describe()
print(summary_stats)
```

## Methodology

The methodology employed to access the ev charging dataset comprised three steps. First, a graphical review of the dataset was completed, see Figure 1 to 10. Second, a statistical analysis of the data was completed using analysis of variance (ANOVA) to complete hypothesis testing to help understanding any relationships between the factors studied, see Figure 11 to 14. Third, regression analysis was completed to build a predictive model of charging cost (USD) as a function of the factors studied and reported within the dataset, see Tables 1 to 9.

### Graphical Review of the Data

Various types of plots were used to graphically review the dataset including boxplots, scatterplots, and correlations plots. To understand the difference or similarities between vehicle models a boxplot of vehicle model vs. battery capacity was created, see Figure 1. The plot indicates all car models appear to have similar battery capacity, see Figure 1. Charge duration as a function of location was also plotted, see Figure 2. Graphically there does not appear to be a significant difference in charge duration across locations, see Figure 2.

Scatterplots were used to understand the relationship between various factors and charging rate, see Figures 3 and 4 Charging rate vs. charging cost was plotted on a scatterplot with hue defining the time of day, see Figure 3. Charging rate vs charging cost was plotted with hue defining charging station location, see Figures 3 and 4 respectively. Neither plot displays any visually apparent relationships between the variables studied.

Histograms were leveraged to help display the distribution of the variables (i) battery capacity, (ii) energy consumed, and (iii) charging rate, see Figures 5, 6, and 7. Battery capacity appears to be three specific categories, 59, 75, and 100 kWh, see Figure 5. Energy consumed (kWh) during charging may be normally distributed with a mean of 40 kWh and a standard deviation of 13 (80/6 = 30 (spread / 6 std. dev.)) with several outliers greater than 80 kWh, see Figure 6. Charging rate may also be normally distributed with a mean of 30 kW and standard deviation of 10 kW (approximately) with several outliers greater than 60 kW, see Figure 7.

A boxplot was used to help understand the relationship between charging cost and time of charge and charger type, see Figure 8. Graphically is appears that charging cost is not influence by time of day or charger type as there appears to be a high variance within each subgroup vs. between subgroups, see Figure 8.

A scatterplot of charging temperature, the outside temperature during charge, and its effect on charging rate is provided in Figure 9. Here hue was defined as the age of the vehicle in years, see Figure 9. The scatterplot, like the previous scatterplots visually did not clearly display a relationship between the variables studied, see Figure 9.

A seaborn pairwise plot is presented in Figure 10. The pairwise plot provides a graphical summary of the entire dataset for ease of attempting to visually determine if there is a relationship or correlation between factors studied. Within the pairwise plot the hue was defined as the vehicle type, see Figure 10. Visually the pairwise plot did not identify any obvious correlations within the dataset, see Figure 10.

```{python}
#| label: Figure1
#| fig-cap: "Battery Capacity (KWh) for Five Models of EV Studied"
plt.figure(figsize=(8,6))
sns.boxplot(data=ev_charging,x='Vehicle Model',y='Battery Capacity (kWh)')
plt.title('\nFigure 1 - Battery Capacity (KWh) for Five Models of EV Studied\n')
plt.xlabel('Vehicle Model Studied')
plt.ylabel('Battery Capacity (kWh)')
plt.show()
```

```{python}
#| label: Figure2
#| fig-cap: "Charging Station Location vs. Charging Duration (hours)"
plt.figure(figsize=(8,6))
sns.boxplot(data=ev_charging,x='Charging Station Location',y='Charging Duration (hours)')
plt.title('\nFigure 2 - Charging Station Location vs. Charging Duration (hours)\n')
plt.xlabel('Charging Station Location')
plt.ylabel('Charge Duration (hours)')
plt.show()
```

```{python}
#| label: Figure3
#| fig-cap: "Charging Rate (kW) vs Charging Cost (USD)"
plt.figure(figsize=(8,6))
sns.scatterplot(data=ev_charging,x='Charging Rate (kW)',y='Charging Cost (USD)',hue='Time of Day')
plt.title('\nFigure 3 - Charging Rate (kW) vs Charging Cost (USD) as a function of Time of Day\n')
plt.xlabel('Charging Rate (kW)')
plt.ylabel('Charging Cost (USD)')
plt.show()

```

```{python}
#| label: Figure4
#| fig-cap: "Charging Station Location vs. Charging Duration (hours)"
plt.figure(figsize=(8,6))
sns.scatterplot(data=ev_charging,x='Charging Rate (kW)',y='Charging Cost (USD)',hue='Charging Station Location')
plt.title('\nFigure 4 - Charging Rate (kW) vs. Charging Cost (USD) as a function of Location \n')
plt.xlabel('Charging Rate (kW)')
plt.ylabel('Chraging Cost (USD)')
plt.show()

```

```{python}
#| label: Figure5
#| fig-cap: "Histogram of Battery Capacity (kWh)"
plt.figure()
sns.histplot(data=ev_charging,x='Battery Capacity (kWh)')
plt.title('\nFigure 5 - Histogram of Battery Capacity (kWh)\n')
plt.xlabel('Battery Capacity (kWh)')
plt.ylabel('Count')
plt.show()
```

```{python}
#| label: Figure6
#| fig-cap: "Histogram of Energy Consumed during Charging (kWh)"
plt.figure()
sns.histplot(data=ev_charging,x='Energy Consumed (kWh)')
plt.title('\nFigure 6 - Histogram of Energy Consumed during Charging (kWh)\n')
plt.xlabel('Energy Consumed')
plt.ylabel('Count')
plt.show()
```

```{python}
#| label: Figure7
#| fig-cap: "Figure 7 - Histogram of Charging Rate (kw)"
plt.figure()
sns.histplot(data=ev_charging,x='Charging Rate (kW)')
plt.title('\nFigure 7 - Histogram of Charging Rate (kw)\n')
plt.show()
```

```{python}
#| label: Figure8
#| fig-cap: "Charging Station Location vs. Charging Duration (hours)"
plt.figure(figsize=(8,6))
sns.boxplot(data=ev_charging,x='Time of Day',y='Charging Cost (USD)',hue='Charger Type')
plt.title('\nFigure 8 - Charging Cost (USD) vs. Time of Day for Three Charger Types\n')
plt.show()

```

```{python}
#| label: Figure9
#| fig-cap: "Charging Station Location vs. Charging Duration (hours)"
plt.figure(figsize=(8,6))
sns.scatterplot(data=ev_charging,x='Temperature (Â°C)',y='Charging Rate (kW)',hue='Vehicle Age (years)')
plt.title('\nFigure 9 - Charging RAte (kW) as a function of Temperature (C) for Vehicles between 0 and 10 years old\n')
plt.show()

```

#### Figure 10 - Seaborn Pair Plot for EV Charging Dataset Variables

```{python}
#| label: Figure10
#| fig-cap: "Seaborn Pair Plot for EV Charging Dataset Variables"
plt.figure()
sns.pairplot(ev_charging,diag_kind='hist',hue='Vehicle Model')
plt.title('\nFigure 10 - Seaborn Pair Plot for EV Charging Dataset Variables\n')
plt.show()

```

## Results

### Statistical Review of the Data

A statistical review of the dataset was completed using analysis of variance (ANOVA). ANOVA was selected to complete hypothesis testing where the test is an expansion of the two-sample t-test but allows for the mean of many subgroups to be compared and for differing sample size within each subgroup. The ANOVA assesses variance sum of squares within a subgroup vs. between subgroups.

Each ANOVA includes a boxplot of the subgroups studied and a p-value. The ANOVA null hypothesis (Ho) is that all subgroups have a common mean value (p-value \> alpha). The ANOVA alternative hypothesis (Ha) is that at least one subgroup has a unique mean (p-value \< alpha). Alpha, the level of significance is typically 0.05 i.e. there is a 5% change of a Type I error - reject Ho when Ho is true - conclude there is a difference in mean when in fact there is no difference.

The first hypothesis test completed was (i) Ho: all vehicle models have the same charging cost vs. Ha: at least one vehicle model has a unique charging cost, see Figure 11. The ANOVA for this hypothesis test yielded a p-value = 0.032, see Figure 11. As a result, Ho is rejected in favor of Ha and we conclude at least one vehicle has a unique charging cost. The ANOVA does not identify which subgroup, vehicle model, has the unique mean and graphically it is not visually apparent what vehicle model is unique, see Figure 11.

The second hypothesis test completed was (ii) Ho: all charging station locations have the same mean charging cost vs. Ha: at least one charging station location has a unique mean charging cost, see Figure 12. The ANOVA yielded a p-value = 0.245 indicating no difference in mean charging cost between charging station locations, see Figure 12.

The third hypothesis test completed examined (iii) Ho: all charger types have the same mean charging cost vs. Ha: at least one charger type has a unique mean charging cost, see Figure 13. The ANOVA yielded a p-value = 0.02 indicating at least one charger type has a unique mean charging cost. Reviewing the boxplot it is not visually apparent what charger type is unique, see Figure 13.

To understand the relationship between charging temperature and charging cost a simple linear regression was completed, see Table 3. The linear regression completes the hypothesis test (iv) Ho: coefficient = 0 vs. Ha: coefficient is not equal to zero. The regression provided an equation for charging cost as a function of temperature, (cost (USD) = 21.7858 + 0.0459 \* Temperature(C)), see Table 3. A scatterplot of temperature and charging cost with the linear regression line is provided in Figure 14. The p-value for the regressor coefficient was less than alpha indicating there exists a statistically significant relationship and increasing temperature results in increased charging cost, see Table 3 and Figure 14.

ANOVA was used to understand how (i) vehicle model, (ii) charging station locations, and (iii) charger type had an effect on charging cost. Charging cost appears to be influenced by vehicle model and charger type, see Figures 11 and 13 respectively. The simple linear regression highlighted the relationship between temperature and charging cost. The results of the statistical analysis helped inform the multivariate regression predictive model building efforts.

```{python}
# ANOVA - does vehicle model influence charging cost? 
# Ho: model does not effect charing cost
# Ha: at least one model has a different charging cost 

model = ev_charging['Vehicle Model'].unique()
print(model)

ev_charging = ev_charging.dropna()

BMW = ev_charging[ev_charging['Vehicle Model'] == model[0]]['Charging Cost (USD)']
Hyundai = ev_charging[ev_charging['Vehicle Model'] == model[1]]['Charging Cost (USD)']
Chevy = ev_charging[ev_charging['Vehicle Model'] == model[2]]['Charging Cost (USD)']
Nissan = ev_charging[ev_charging['Vehicle Model'] == model[3]]['Charging Cost (USD)']
Tesla = ev_charging[ev_charging['Vehicle Model'] == model[4]]['Charging Cost (USD)']

f_statistic, p_value = stats.f_oneway(BMW, Hyundai, Chevy, Nissan, Tesla)

```

```{python}
#| label: Figure11
#| fig-cap: "ANOVA vehicle model vs charging cost"
plt.figure()
sns.boxplot(data=ev_charging,x='Vehicle Model',y='Charging Cost (USD)')
plt.title(f'Figure 11 - Analysis of Variance: Charging Cost (USD) vs. Vehicle Model\n(P-value = {p_value:3.3f})')
plt.show()

```

```{python}
# ANOVA - does charging location influence charging cost? 
# Ho: charging location does not effect charing cost
# Ha: at least one location  has a different charging cost 

model = ev_charging['Charging Station Location'].unique()
print(model)

ev_charging = ev_charging.dropna()

Houston = ev_charging[ev_charging['Charging Station Location'] == model[0]]['Charging Cost (USD)']
SF = ev_charging[ev_charging['Charging Station Location'] == model[1]]['Charging Cost (USD)']
LA = ev_charging[ev_charging['Charging Station Location'] == model[2]]['Charging Cost (USD)']
Chicago = ev_charging[ev_charging['Charging Station Location'] == model[3]]['Charging Cost (USD)']
NY = ev_charging[ev_charging['Charging Station Location'] == model[4]]['Charging Cost (USD)']

f_statistic, p_value = stats.f_oneway(Houston, SF, LA, Chicago, NY)

print('P-value:',p_value)

```

```{python}
#| label: Figure12
#| fig-cap: "ANOVA: Charging Location vs Charging Cost"
plt.figure()
sns.boxplot(data=ev_charging,x='Charging Station Location',y='Charging Cost (USD)')
plt.title(f'Figure 12 - Analysis of Variance: Charging Cost (USD) vs. Charging Location\n(P-value = {p_value:3.3f})')
plt.show()

```

```{python}
# ANOVA - does the type of charger influence charging cost? 
# Ho: type of charger does not effect charing cost
# Ha: at least one charger type has a uniqeu or different mean charging cost 

model = ev_charging['Charger Type'].unique()
print(model)

ev_charging = ev_charging.dropna()

FAST = ev_charging[ev_charging['Charger Type'] == model[0]]['Charging Cost (USD)']
Level_1 = ev_charging[ev_charging['Charger Type'] == model[1]]['Charging Cost (USD)']
Level_2 = ev_charging[ev_charging['Charger Type'] == model[2]]['Charging Cost (USD)']


f_statistic, p_value = stats.f_oneway(FAST, Level_1,Level_2)

print('P-value:',p_value)

```

```{python}
#| label: Figure13
#| fig-cap: "ANOVA: Charger Type vs Charging Cost"
plt.figure()
sns.boxplot(data=ev_charging,x='Charger Type',y='Charging Cost (USD)')
plt.title(f'Figure 13: ANOVA - Charger Type vs. Charging Cost (USD)\n(p-value = {p_value:3.2f})')
plt.show()
```

#### Table 3 - Linear Regression: Charging Cost (USD) as a function of Temperature (C)

```{python}
# linear regression - does charging temperature have an effect on charging cost? 
# Ho: linear regression coefficient = 0
# Ha: linear regression coefficient is not equal to 0

X = ev_charging[['Temperature (Â°C)']]

y = ev_charging['Charging Cost (USD)']

X = sm.add_constant(X)

model = sm.OLS(y,X).fit()

print(model.summary())

p_value_temp = model.pvalues['Temperature (Â°C)']
print(f"\nP-value for Temperature (Â°C): {p_value_temp:.5f}")

```

```{python}
#| label: Figure14
#| fig-cap: "Linear Regression: Temperature vs Charging Cost"
plt.figure(figsize=(10,6))
sns.regplot(
    data=ev_charging, 
    x='Temperature (Â°C)', 
    y='Charging Cost (USD)', 
    ci=None,      
    line_kws={"color": "red"},  
    scatter_kws={"alpha": 0.6} 
)
plt.title("Figure 14: Linear Regression - Charging Cost vs Temperature (C)\nregression equation: Charging Cost (USD) = 21.7858 + 0.0459* Temperature (C)\nRegressor Coefficient P-value = 0.035",fontsize=10)
plt.xlabel("Temperature (Â°C)")
plt.ylabel("Charging Cost (USD)")
plt.show()
```

### Predictive Model Building

An attempt was made to build a predictive model of charging cost as a function of the factors studied within the dataset using multivariate regression analysis. The multivariate regression analysis was completed in three iterations. The first iteration included all factors in the dataset, see Table 4a and 4b. The second iteration included only those terms that appear to be statistically significant, to improve the R-sq-adjusted value by removing non-significant parameters from the model, see Table 5. The third iteration was a refinement of the regression model, again reducing the number of terms to attempt a model with a high value for R-sq-adjusted, see Table 6.

The initial regression model included all the terms within the EV charging dataset, see Table 4b. The categorical variables were transformed to numerical values using one-hot-encoding, see Table 4b. That first model provided an empirical model of charging cost as a function of all variables studied with an R-sq-adjusted of 0.017 meaning the model explained 1.7% of the variance within the dataset.

To improve the R-sq-adjusted value a majority of the non-significant factors were removed from the model, see Table 5. This second model provided an R-sq-adjusted value of 0.021, that is the model explained 2.1% of the variance within the dataset.

A third multivariate regression model was attempted, again removing non-significant (p-value \> 0.05) terms from the model in an attempt to improve R-sq-adjusted by including only statistically significant terms in the model, see Table 6. The third model yielding an R-sq-adjusted = 0.018 - typically an R-sq-adj value greater than 0.7 or 70% is desired.

The results of the multivariate regression analysis were disappointing, none of the model attempts yielded an R-sq-adjusted above 50%. As a result, the support vector machine (SVM) algorithm was attempted to predict charging cost as a function of the other variables or columns in the dataset, see Tables 7, 8 and 9.The initial SVM model included only numerical factors and provided an R-sq-adjusted of -0.25, see Table 7. The second SVM attempt included all factors, numerical and categorical, one-hot-encoding was used to transform categorical factors to numerical, and grid search employed to optimize the RBF kernel hyper-parameters, see Table 8. A third SVM attempt also included all factors and grid search employed to optimize the polynomial kernel, see Table 9. In both SVM's the data was scaled to ensure a uniform range for each variable studied. However, the second model, even with grid search, yielded a low value for R-sq-adjusted of -0.39 indicating the model was no better than a simple linear regression.

The empirical modeling effort included multivariate regression and support vector machine analysis. The best performing model was a multivariate regression analysis that included only statistically significant terms and provided an R-sq = 0.041 and R-sq-adjusted = 0.021. The results of the predictive model building were disappointing and may need an expert review to ensure no technical errors in the code were made.

```{python}
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import PolynomialFeatures

```

```{python}
ev_charging = ev_charging.dropna()
```

#### Table 4a - Initial Multivariable Regression Analysis: Charging Cost (USD) MSE and R-squared

```{python}

X = ev_charging[['Vehicle Model','Battery Capacity (kWh)','Charging Station Location','Energy Consumed (kWh)','Charging Duration (hours)','Charging Rate (kW)','Time of Day','Day of Week','State of Charge (Start %)','State of Charge (End %)','Distance Driven (since last charge) (km)','Temperature (Â°C)','Vehicle Age (years)','Charger Type','User Type']]

y = ev_charging['Charging Cost (USD)']


num_variables = ['Battery Capacity (kWh)','Energy Consumed (kWh)','Charging Duration (hours)','Charging Rate (kW)','State of Charge (Start %)','State of Charge (End %)','Distance Driven (since last charge) (km)','Temperature (Â°C)','Vehicle Age (years)']

cat_variables = ['Vehicle Model','Charging Station Location','Time of Day','Day of Week','Charger Type','User Type']

# Preprocessing for numerical and categorical features
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), num_variables),
        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_variables)
    ]
)

# defining the model architecture 
model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('regressor', LinearRegression())
])

# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# Update pipeline with scaled target
model.fit(X_train, y_train)
y_pred = model.predict(X_test)



# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print('Table 4a - Initial Multivariable Regression Analysis: Charging Cost (USD) MSE and R-squared')
print(f"Mean Squared Error: {mse:.2f}")
print(f"R-squared: {r2:.2f}")
```

#### Table 4b - Initial Multivariable Regression Analysis: Charging Cost (USD) Model Summary

```{python}

X = ev_charging[['Vehicle Model','Battery Capacity (kWh)','Charging Station Location','Energy Consumed (kWh)','Charging Duration (hours)','Charging Rate (kW)','Time of Day','Day of Week','State of Charge (Start %)','State of Charge (End %)','Distance Driven (since last charge) (km)','Temperature (Â°C)','Vehicle Age (years)','Charger Type','User Type']]

y = ev_charging['Charging Cost (USD)']


# one-hot-encoding of categorical variables 
X = pd.get_dummies(X, drop_first=True, dtype=float)

# adding a constant to enable calc. of intercept 
X = sm.add_constant(X)

# fititng the model 
model = sm.OLS(y,X).fit()
print('Table 4b - Initial Multivariable Regression Analysis: Charging Cost (USD) Model Summary')
print(model.summary())


```

#### Table 5 - Second Iteration, Statistically Significant Factors, Multivariable Regression Analysis

```{python}
## removing non-significant terms to improve R2_adj

X = ev_charging[['Vehicle Model','Charging Station Location','Time of Day','Day of Week','State of Charge (End %)','Temperature (Â°C)','Charger Type','User Type']]

y = ev_charging['Charging Cost (USD)']

X = pd.get_dummies(X, drop_first=True, dtype=float)
X = sm.add_constant(X)

model = sm.OLS(y,X).fit()
print('Table 5 - Second Iteration, Statistically Significant Factors, Multivariable Regression Analysis')
print(model.summary())

```

#### Table 6 - Third Iteration, Statistically Significant Factors, Multivariable Regression Analysis

```{python}
## removing additonal non-significant terms to improve R2_adj

X = ev_charging[['Vehicle Model','Charging Station Location','State of Charge (End %)','Temperature (Â°C)','Charger Type','User Type']]

y = ev_charging['Charging Cost (USD)']

X = pd.get_dummies(X, drop_first=True, dtype=float)
X = sm.add_constant(X)

model = sm.OLS(y,X).fit()
print('Table 6 - Third Iteration, Statistically Significant Factors, Multivariable Regression Analysis')
print(model.summary())

```

#### Table 7 - Support Vector Machine: All Factors with One-Hot-Encoding and Grid Search Linear, RBF, and Polynomial Kernels

```{python}
# initial attempt at a SVM model to improve the model performance vs. multivariable regression 
# using Support Vector Regression (SVR)

import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.svm import SVR
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score

# Features and target
X = ev_charging[['Vehicle Model', 'Battery Capacity (kWh)', 'Charging Station Location',
                 'Energy Consumed (kWh)', 'Charging Duration (hours)', 'Charging Rate (kW)',
                 'Time of Day', 'Day of Week', 'State of Charge (Start %)',
                 'State of Charge (End %)', 'Distance Driven (since last charge) (km)',
                 'Temperature (Â°C)', 'Vehicle Age (years)', 'Charger Type', 'User Type']]

y = ev_charging['Charging Cost (USD)']

# One-hot encoding of categorical variables
X = pd.get_dummies(X, drop_first=True, dtype=float)

# Splitting data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scaling the data
scaler_X = StandardScaler()
scaler_y = StandardScaler()

X_train_scaled = scaler_X.fit_transform(X_train)
X_test_scaled = scaler_X.transform(X_test)

y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).ravel()

# SVR with Grid Search parameters
svr = SVR()
param_grid = {
    'kernel': ['linear', 'rbf', 'poly'],
    'C': [0.1, 1, 10],
    'epsilon': [0.01, 0.1, 1],
    'gamma': ['scale', 'auto']
}

# Grid Search
grid_search = GridSearchCV(svr, param_grid, cv=5, scoring='r2', verbose=1)
grid_search.fit(X_train_scaled, y_train_scaled)

# Best estimator
best_model = grid_search.best_estimator_

# Predict on test data
y_pred_scaled = best_model.predict(X_test_scaled)

# Inverse transform predictions and target
y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()
y_test_inv = y_test.values  # Original y_test for evaluation

# Calculate metrics
mse = mean_squared_error(y_test_inv, y_pred)
r2 = r2_score(y_test_inv, y_pred)

# Calculate Adjusted R-squared
n = X_test.shape[0]  # Number of test samples
k = X_test.shape[1]  # Number of predictor variables
r2_adjusted = 1 - ((1 - r2) * (n - 1) / (n - k - 1))

# Print Results
print("===== Kernel: linear, rbf, poly: Model Summary =====")
print("Best Hyperparameters:", grid_search.best_params_)
print("\nPerformance Metrics:")
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"RÂ² Score: {r2:.2f}")
print(f"Adjusted RÂ² Score: {r2_adjusted:.2f}")
print("\nBest Estimator:")
print(best_model)

```

#### Table 8 - Support Vector Machine: All Factors with One-Hot-Encoding and Grid Search RBF Kernel Hyperparameters

```{python}
# trying to optimize the SVM RBF kernal to achieve a half decent model 

from sklearn.model_selection import GridSearchCV

X = ev_charging[['Vehicle Model','Battery Capacity (kWh)','Charging Station Location',
                 'Energy Consumed (kWh)','Charging Duration (hours)','Charging Rate (kW)',
                 'Time of Day','Day of Week','State of Charge (Start %)',
                 'State of Charge (End %)','Distance Driven (since last charge) (km)',
                 'Temperature (Â°C)','Vehicle Age (years)','Charger Type','User Type']]

y = ev_charging['Charging Cost (USD)']

# one-hot-encoding of categorical variables 
X = pd.get_dummies(X, drop_first=True, dtype=float)

# splitting data in to training and test datasets 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scaling the data
scaler_X = StandardScaler()
scaler_y = StandardScaler()

X_train_scaled = scaler_X.fit_transform(X_train)
X_test_scaled = scaler_X.transform(X_test)

y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).ravel()

# SVM grid search parameters 
svr = SVR()
param_grid = {
    'kernel': ['rbf'],
    'C': [0.1, 1, 10, 100, 1000],
    'gamma': ['scale', 'auto', 0.01, 0.1, 1]
}

# Grid Search
grid_search = GridSearchCV(svr, param_grid, cv=5, scoring='r2', verbose=1)
grid_search.fit(X_train_scaled, y_train_scaled)

# Best estimator
best_model = grid_search.best_estimator_

# Predict on test data
y_pred_scaled = best_model.predict(X_test_scaled)

# Inverse transform predictions and target
y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()
y_test_inv = y_test.values  # Original y_test for evaluation

# Calculate metrics
mse = mean_squared_error(y_test_inv, y_pred)
r2 = r2_score(y_test_inv, y_pred)

# Calculate Adjusted R-squared
n = X_test.shape[0]  # Number of test samples
k = X_test.shape[1]  # Number of predictor variables
r2_adjusted = 1 - ((1 - r2) * (n - 1) / (n - k - 1))

# Print Results
print("===== RBF Kernel: Model Summary =====")
print("Best Hyperparameters:", grid_search.best_params_)
print("\nPerformance Metrics:")
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"RÂ² Score: {r2:.2f}")
print(f"Adjusted RÂ² Score: {r2_adjusted:.2f}")
print("\nBest Estimator:")
print(best_model)

```

#### Table 9 - Support Vector Machine: All Factors with One-Hot-Encoding and Grid Search Polynomial Kernel Hyperparameters

```{python}
# trying to optimize the SVM poly kernal to improve model performance

from sklearn.model_selection import GridSearchCV

X = ev_charging[['Vehicle Model','Battery Capacity (kWh)','Charging Station Location',
                 'Energy Consumed (kWh)','Charging Duration (hours)','Charging Rate (kW)',
                 'Time of Day','Day of Week','State of Charge (Start %)',
                 'State of Charge (End %)','Distance Driven (since last charge) (km)',
                 'Temperature (Â°C)','Vehicle Age (years)','Charger Type','User Type']]

y = ev_charging['Charging Cost (USD)']

# one-hot-encoding of categorical variables 
X = pd.get_dummies(X, drop_first=True, dtype=float)

# splitting data in to training and test datasets 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scaling the data
scaler_X = StandardScaler()
scaler_y = StandardScaler()

X_train_scaled = scaler_X.fit_transform(X_train)
X_test_scaled = scaler_X.transform(X_test)

y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).ravel()

# SVM grid search parameters 
svr = SVR()
param_grid = {
    'kernel': ['poly'],         
    'C': [0.1, 1, 10, 100],       
    'degree': [2, 3, 4, 5],      
    'gamma': ['scale', 'auto']
}

# Grid Search
grid_search = GridSearchCV(svr, param_grid, cv=5, scoring='r2', verbose=1)
grid_search.fit(X_train_scaled, y_train_scaled)

# Best estimator
best_model = grid_search.best_estimator_

# Predict on test data
y_pred_scaled = best_model.predict(X_test_scaled)

# Inverse transform predictions and target
y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()
y_test_inv = y_test.values  # Original y_test for evaluation

# Calculate metrics
mse = mean_squared_error(y_test_inv, y_pred)
r2 = r2_score(y_test_inv, y_pred)

# Calculate Adjusted R-squared
n = X_test.shape[0]  # Number of test samples
k = X_test.shape[1]  # Number of predictor variables
r2_adjusted = 1 - ((1 - r2) * (n - 1) / (n - k - 1))

print("===== Kernel = Poly: Model Summary =====")
print("Best Hyperparameters:")
print(grid_search.best_params_)
print("\nPerformance Metrics:")
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"RÂ² Score: {r2:.2f}")
print(f"Adjusted RÂ² Score: {r2_adjusted:.2f}")
print("\nBest Estimator:")
print(best_model)

```

## Discussion

The term project comprised an analysis of an electric vehicle charging dataset, see Tables 1 and 2. The analysis of the dataset, to understand what variables influenced charging cost was completed in stages. First, a graphical assessment of the data was completed, see Figures 1 to 10. Second, a statistical review leveraging analysis of variance (ANOVA) was completed to try and understand or isolated variables that might have an effect on charging cost, see Figures 11 to 14. Next empirical models were created and refined to predict charging cost as a function of the other variables in the dataset, see Tables 1 and 2. The modeling effort included both multivariate regression analysis and support vector machine algorithms. The results of the regression analysis is provided in Tables 4, 5 and 6. The results of the support vector machine algorithms are presented in Tables 7 and 8.

The electric vehicle charging dataset comprised 1320 rows of data and 20 columns. Each row was a charging event with various data documented in the columns, see Tables 1 and 2. The graphical assessment of the dataset did not reveal any obvious trends with respect to charging cost, see Figures 1 to 10.

The statistical analysis of the data was completed using analysis of variance to compare the means across multiple subgroups, see Figures 11, 12, and 13. That work indicated that vehicle type and charger type had an effect on charging cost, or at least one subgroup in each analysis had an unique mean, see Figures 11 and 13 respectively. Temperature was a continuous variable; as a result, simple linear regression was used to determine the relationship between temperature and charging cost, see Table 3. That work indicated temperature did influence charging cost, increasing temperature increased the cost of charging, see Table 3 and Figure 14.

Multivariable regression analysis was used to create predictive models of charging cost as a function of the other variables in the dataset, see Tables 4, 6, and 6. The regression analysis included both continuous numerical variables and categorical variables, the categorical variables were transformed to numerical values using one-hot-encoding. The regression analysis approach was iterative. The first model included all the factors in the dataset and yielded an R-sq-adjusted of 0.017 indicating the model explained 1.7% of the variance in the dataset, see Tables 4a and 4b. Ideally, an R-sq-adjusted \> 70% would be preferred for a well performing predictive model. The performance of regression model was improved by removing non-significant terms, see Tables 5 and 6. However, the best performing model had an R-sq-adjusted value of 0.021 or 2.1%.

In an effort to create an improved predictive model the support vector machine (SVM) algorithm was attempted, see Tables 7, 8 and 9. The initial SVM model included only numerical factors to create a predictive model of charging cost; however, that model also yielded a low R-sq-adjusted value of -0.25, see Table 7. To improve the SVM algorithm performance a second attempt was made. That second attempt included both numerical and categorical factors, one-hot-encoding was used to transform categorical factors to numerical, and the RBF kernel implement, see Table 8. The data was scaled using the standard scalar to ensure a uniform range across all factors. To find optimum SVM parameters a grid search was included. Here too the model performed poorly providing an R-sq-adjusted of -0.39 indicating the SVM was no better than linear regression, see Table 8. A third attempt using the polynomial kernel and grid search to optimizes hyper-parameters did not yield improved results, see Table 9. The SVM regression did not perform as well as the multi-variable regression perhaps because the dataset was simply not large enough or the dataset is not well suited to the SVM algorithm.

## Conclusions

The ChilePeppers team completed an assessment of an electric vehicle charging dataset. The dataset provided a record of 1320 charging events and recording 20 parameters for each event. The analysis was completed in stages. First a graphical review of the dataset was completed. Then a statistical review was leveraged to complete hypothesis testing using both ANOVA and regression analysis to understand or identify charging factors that influence the charging cost. Next predictive models were attempted to estimate the charging cost as a function of the other parameters in the dataset using both multivariate regression and support vector machine algorithms. The statistical analysis identified vehicle type and charger type as influencing charging cost. The predictive models while yielding empirical models or equations provided algorithms with very low values for R-sq and R-sq-adjusted. The multi-variable regression analysis provided a model with R-squared-adusted = 2.1% and the support vector machine regression algorithm provided a negative value for R-squared-adjusted. Ideally an empirical model would be characterized by an R-squared adjusted greater than 70% indicating the model explains more than 70% of the variance in the dataset. In this example the models are not capable of predicting charging cost as a function of the variables studied. 